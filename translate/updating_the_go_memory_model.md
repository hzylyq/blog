# Updating the Go Memory Model

当前的 Go 语言内存模型是在 2009 年编写的，此后进行了小幅更新。 很明显，至少有一些细节我们应该添加到当前的内存模型中，其中包括对竞争检测器的明确认可以及对 sync/atomic 的 API 如何运行的明确说明。

这篇文章重申了 Go 的整体理念和当前的内存模型，然后概述了我认为应该对 Go 内存模型进行的相对较小的调整。 它假设了之前文章“[硬件内存模型](https://research.swtch.com/hwmm)”和“[编程语言内存模型](https://research.swtch.com/plmm)”中介绍的背景。

我已经打开了一个 [GitHub 讨论](https://github.com/golang/go/discussions/47141)来收集对这里提出的想法的反馈。 基于这些反馈，我打算在本月晚些时候准备一份正式的 Go 提案。 使用 GitHub 讨论本身就是一个实验，继续尝试找到一[种合理的方式来扩大对重要变化的讨论](https://research.swtch.com/proposals-discuss)。



## Go's Design Philosophy(GO 设计哲学)

Go 旨在成为构建实用、高效系统的编程环境。它对于小型项目较为轻量，但也可以优雅地扩展到大型项目和大型工程团队。

Go 鼓励在高层次上接近并发，特别是通过通信。Go 的第一个[谚语](https://go-proverbs.github.io/)是“不要通过共享内存进行通信。 通过通信访问内存。” 另一个流行的谚语是“清晰胜于聪明”。 换句话说，Go 鼓励通过避免微妙的代码来避免微妙的错误。

Go 的目标不仅是可理解的程序，而且是可理解的语言和可理解的包 API。复杂或微妙的语言特性或 API 与该目标相矛盾。 正如托尼·霍尔在 1980 年图灵奖演讲中所说:  [1980 Turing award lecture](https://www.cs.fsu.edu/~engelen/courses/COP4610/hoare.pdf):

​	我的结论是，有两种构建软件设计的方法：一种方法是让它简单到没有明显缺陷，另一种方法是使它复杂到没有明显缺陷。

​    第一种方法要困难得多。它需要与发现构成复杂自然现象的简单物理定律相同的技能、奉献精神、洞察力甚至灵感。 它还需要愿意接	受受到物理、逻辑和技术约束的目标，并在无法满足相互冲突的目标时接受妥协。

这与 Go 的 API 哲学非常吻合。我们通常会在设计过程中花费很长时间来确保 API 是正确的，并努力将其减少到最小、最有用的本质。

Go 作为一个有用的编程环境的另一个方面是对最常见的编程错误具有明确定义的语义，这有助于理解和调试。 这个想法并不新鲜。 再次引用 Tony Hoare 的话，这一次来自他 1972 年的“[软件质量](https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380020202)”清单:

​		除使用起来非常简单外，软件程序还必须很难被误用； 它必须善待编程错误，清楚地表明它们的发生，并且永远不会变得不可预	        测。

为有缺陷的程序定义明确语义的常识并不像人们想象的那样普遍。在 C/C++ 中，未定义的行为已经演变成一种编译器作者的全权委托，以更加有趣的方式将稍微有错误的程序变成非常不同的有错误的程序。 Go 没有采用这种方法：没有“未定义的行为”。特别是，空指针解引用、整数溢出和无意的无限循环等错误都在 Go 中定义了语义。



## [Go's Memory Model Today](https://research.swtch.com/gomm#gos_memory_model_today)

Go 的内存模型从以下建议开始，与 Go 的整体理念一致：

​	修改多个 goroutine 同时访问的数据的程序必须序列化这种访问。
​    要序列化访问，请使用通道操作或其他同步原语（例如 sync和sync/atomic 包中的原语）以保护数据。
​    如果您必须阅读本文档的其余部分才能了解您的程序的行为，那么您就太聪明了。
​    不要聪明。

这仍然是很好的建议。 该建议也与其他语言对 DRF-SC 的鼓励一致：同步以消除数据竞争，然后程序将表现得好像顺序一致，无需了解内存模型的其余部分。

在这个建议之后，Go 内存模型定义了一个传统的基于之前发生的读取和写入的定义。 就像在 Java 和 JavaScript 中一样，Go 中的读取可以观察任何较早但尚未覆盖的写入，或者任何竞速写入； 安排只有一个这样的写入强制特定的结果。



然后，内存模型继续定义建立跨协程发生前边缘的同步操作。 操作是通常的操作，带有一些 Go 特定的风味：

​	如果包 p 导入包 q，则 q 的 init 函数的完成发生在任何 p 的开始之前。

​	main.main 函数的启动发生在所有 init 函数完成之后。

​	启动新 goroutine 的 go 语句发生在 goroutine 开始执行之前。

​	通道上的发送发生在来自该通道的相应接收完成之前。

​	通道的关闭发生在由于通道关闭而返回零值的接收之前。

​	来自无缓冲通道的接收发生在该通道上的发送完成之前。

​	容量为 C 的通道上的第 k 个接收发生在来自该通道的第 k+C 个发送完成之前。

​	对于任何sync.Mutex 或sync.RWMutex 变量l 且n < m，l.Unlock() 的n 调用发生在l.Lock() 的调用m 返回之前。

​	从 once.Do(f) 对 f() 的单个调用发生（返回）在任何对 once.Do(f) 的调用返回之前。

该列表明显省略了同步/原子以及包同步中更新的 API 的任何提及。

内存模型以一些不正确同步的例子结束。 它不包含错误编译的示例。

## [Changes to Go's Memory Model](https://research.swtch.com/gomm#changes_to_gos_memory_model)

2009 年，在我们着手编写 Go 的内存模型时，Java 内存模型进行了新的修订，C/C++11 内存模型正在最终确定。 一些人强烈鼓励我们采用 C/C++11 模型，充分利用其中的所有工作。 这对我们来说似乎很冒险。 取而代之的是，我们决定采用更保守的方法来保证我们将做出的保证，随后十年的论文证实了这一决定，这些论文详细介绍了 Java/C/C++ 内存模型系列中非常微妙的问题。 定义足够多的内存模型来指导程序员和编译器作者很重要，但是完全正式地定义一个模型——正确！——似乎仍然超出了最有才华的研究人员的掌握范围。  Go 继续说明有用的最低要求就足够了。

本节列出了我认为我们应该做出的调整。 如前所述，我打开了一个 GitHub 讨论来收集反馈。 基于这些反馈，我计划在本月晚些时候准备一份正式的 Go 提案。

### [Document Go's overall approach](https://research.swtch.com/gomm#document_gos_overall_approach)

自编写内存模型以来，新的 API 已添加到同步包中。 我们需要将它们添加到内存模型中（issue #7948）。 值得庆幸的是，这些添加看起来很简单。 我相信它们如下。

​	对于sync.Cond：广播或信号发生在它解除阻塞的任何等待调用返回之前。
​    对于sync.Map：Load、LoadAndDelete 和LoadOrStore 是读取操作。  Delete、LoadAndDelete 和 Store 是写操作。  LoadOrStore 是一个写操作，当它返回加载设置为 false 时。 写入操作发生在任何观察写入效果的读取操作之前。
​    对于sync.Pool：在调用Get 之前调用Put(x) 会返回相同的值x。 类似地，调用 New 返回 x 发生在调用 Get 返回相同值 x 之前。
​    对于sync.WaitGroup：在它解除阻塞的任何Wait 调用返回之前，会调用Done。

这些 API 的用户需要了解这些保证才能有效地使用它们。 因此，虽然我们应该将文本保留在内存模型中以进行说明，但我们也应该将其包含在包同步的文档注释中。 这也将有助于为第三方同步原语树立一个例子，说明记录 API 建立的排序保证的重要性。



### [Document happens-before for sync/atomic](https://research.swtch.com/gomm#document_happens-before_for_sync/atomic)

内存模型中缺少原子操作。 我们需要添加它们（问题 #5045）。 我相信我们应该说：

​	sync/atomic 包中的 API 统称为“原子操作”，可用于同步不同 goroutine 的执行。 如果原子操作 B 观察到原子操作 A 的效果，则 A 发生在 B 之前。程序中执行的所有原子操作的行为就像以某种顺序一致的顺序执行一样。

这是 [Dmitri Vyukov 在 2013 年提出的建议](https://github.com/golang/go/issues/5045#issuecomment-66076297) 和 [我在 2016 年非正式的承诺](https://github.com/golang  /go/issues/5045#issuecomment-252730563）。 它还具有与 Java 的 `volatile` 和 C++ 的默认原子相同的语义。

在 C/C++ 菜单方面，同步原子只有两种选择：顺序一致或获取/释放。  （宽松的原子不会创建发生在边缘之前，因此没有同步效果。）这些之间的决定归结为，首先，能够推理多个位置上原子操作的相对顺序有多重要，以及， 其次，与获取/释放原子相比，顺序一致原子要贵多少。

首先，推理多个位置上原子操作的相对顺序非常重要。 在之前的一篇博文中，我给出了一个条件变量的示例，其中包含使用两个原子变量实现的无锁快速路径，通过使用获取/释放原子来破坏。 这种模式一次又一次地出现。 例如，sync.WaitGroup 的过去实现使用了一对原子 uint32 值 wg.counter 和 wg.waiters。 信号量的 Go 运行时实现也依赖于两个独立的原子词，即信号量值 *addr 和对应的等待计数 root.nwait。 还有更多。 在没有顺序一致语义的情况下（即如果我们改用获取/释放语义），人们仍然会写这样的代码； 它只会在某些情况下神秘地失败。

根本问题是，使用获取/释放原子使程序无数据竞争并不会导致程序以顺序一致的方式运行，因为原子本身不会。 也就是说，此类程序不提供 DRF-SC。 这使得此类程序很难推理，因此很难正确编写。

在第二个考虑因素中，如前文所述，硬件设计人员开始为顺序一致的原子提供直接支持。 例如，ARMv8 增加了 ldar 和 stlr 指令用于实现顺序一致的原子，它们也是获取/释放原子的推荐实现。 如果我们为同步/原子采用获取/释放语义，那么在 ARMv8 上编写的程序无论如何都会获得顺序一致性。 这无疑会导致程序意外地依赖于较强的排序，从而在较弱的平台上崩溃。 如果在实践中由于竞争窗口很小而难以观察到获取/释放和顺序一致原子之间的差异，这甚至可能发生在单个架构上。

这两种考虑都强烈建议我们应该采用顺序一致的原子而不是获取/释放原子：顺序一致的原子更有用，一些芯片已经完全缩小了这两个层次之间的差距。 如果差距很大，想必其他人也会这样做。
    出于相同的考虑，以及 Go 拥有最少、易于理解的 API 的总体理念，反对将获取/发布作为附加的并行 API 集提供。 似乎最好只提供最容易理解、最有用、最容易误用的一组原子操作。



另一种可能性是提供原始屏障而不是原子操作。  （当然，C++ 提供了两者。）障碍的缺点是使期望不那么明确，并且在某种程度上更加特定于体系结构。  Hans Boehm 的页面“为什么原子具有集成的排序约束”提出了提供原子而不是障碍的论据（他使用术语围栏）。 一般来说，原子比栅栏更容易理解，而且由于我们今天已经提供了原子操作，我们不能轻易删除它们。 拥有一种机制比拥有两种机制更好。



### [Maybe: Add a typed API to sync/atomic](https://research.swtch.com/gomm#maybe)

上面的定义说，当一个特定的内存块必须被多个 goroutines 并发访问而没有其他同步时，消除竞争的唯一方法是让所有访问都使用原子。 仅仅让部分访问使用原子是不够的。 例如，与原子读或写并发的非原子写仍然是一场竞赛，与非原子读或写并发的原子写也是如此。
    因此，是否应该使用原子访问特定值是该值的属性，而不是特定访问的属性。 因此，大多数语言都将此信息放在类型系统中，例如 Java 的 volatile int 和 C++ 的 atomic<int>。  Go 的当前 API 没有，这意味着正确的使用需要仔细注释结构或全局变量的哪些字段只能使用原子 API 访问。
    为了提高程序的正确性，我开始认为 Go 应该定义一组类型化的原子值，类似于当前的 atomic.Value：Bool、Int、Uint、Int32、Uint32、Int64、Uint64 和 Uintptr。 与 Value 一样，它们也有 CompareAndSwap、Load、Store 和 Swap 方法。 例如：

```go
type Int32 struct { v int32 }

func (i *Int32) Add(delta int32) int32 {
	return AddInt32(&i.v, delta)
}

func (i *Int32) CompareAndSwap(old, new int32) (swapped bool) {
	return CompareAndSwapInt32(&i.v, old, new)
}

func (i *Int32) Load() int32 {
	return LoadInt32(&i.v)
}

func (i *Int32) Store(v int32) {
	return StoreInt32(&i.v, v)
}

func (i *Int32) Swap(new int32) (old int32) {
	return SwapInt32(&i.v, new)
}
```

我将 Bool 包含在列表中，因为我们在 Go 标准库（在未导出的 API 中）中多次使用原子整数构造了原子布尔值。 显然是有需要的。
   我们还可以利用即将到来的泛型支持，并为原子指针定义一个 API，该 API 在其 API 中是类型化的并且没有包不安全： 

```go
type Pointer[T any] struct { v *T }

func (p *Pointer[T]) CompareAndSwap(old, new *T) (swapped bool) {
	return CompareAndSwapPointer(... lots of unsafe ...)
}
```

（等等。）为了回答一个明显的建议，我认为没有一种干净的方法可以使用泛型来提供单个 `atomic.Atomic[T]` 来避免引入 `Bool`、`Int`、 等等作为单独的类型，至少在编译器中不是没有特殊情况。 没关系。

### [Maybe: Add unsynchronized atomics](https://research.swtch.com/gomm#maybe)

所有其他现代编程语言都提供了一种方法来进行并发内存读取和写入，既不会同步程序，也不会使其无效（不算作数据竞争）。  C、C++、Rust 和 Swift 具有宽松的原子性。  Java 有 VarHandle 的“普通”模式。  JavaScript 具有对 SharedArrayBuffer（唯一的共享内存）的非原子访问。  Go没有办法做到这一点。 也许应该。 我不知道。
    如果我们想添加非同步原子读写，我们可以向类型化原子添加 UnsyncAdd、UnsyncCompareAndSwap、UnsyncLoad、UnsyncStore 和 UnsyncSwap 方法。 将它们命名为“unsync”可以避免“relaxed”这个名称带来的一些问题。 首先，有些人使用轻松作为相对比较，如“获取/释放是比顺序一致性更轻松的内存顺序”。 您可以争辩说这不是该术语的正确用法，但它确实发生了。 其次，更重要的是，这些操作的关键细节不是操作本身的内存顺序，而是它们对程序其余部分的同步没有影响的事实。 对于不是内存模型专家的人来说，看到 UnsyncLoad 应该清楚地表明没有同步，而 RelaxedLoad 可能不会。  Unsync 看起来像 Unsafe，这也很好。
    有了 API，真正的问题是是否要添加这些。 提供非同步原子的通常论据是，它对某些数据结构中的快速路径的性能确实很重要。 我的总体印象是它在非 x86 架构上最重要，尽管我没有数据来支持这一点。 不提供不同步的原子可以被认为是对这些架构的惩罚。

反对提供非同步原子的一个可能的论点是，在 x86 上，忽略潜在的编译器重新排序的影响，未同步的原子与获取/释放原子无法区分。 因此，他们可能会被滥用来编写仅适用于 x86 的代码。 反驳是这种诡计不会通过竞争检测器的验证，它实现了实际的内存模型而不是 x86 内存模型。
    由于我们今天缺乏证据，我们没有理由添加此 API。 如果有人强烈认为我们应该添加它，那么证明这种情况的方法是收集以下证据：（1）程序员需要编写的代码的普遍适用性，以及（2）广泛使用的系统的显着性能改进来自使用 非同步原子。  （最好使用 Go 以外的语言的程序来展示这一点。）

### [Document disallowed compiler optimizations](https://research.swtch.com/gomm#document_disallowed_compiler_optimizations)

当前的内存模型以给出无效程序的例子结束。 由于内存模型充当程序员和编译器编写者之间的契约，我们应该添加无效编译器优化的示例。 例如，我们可以添加：

[Incorrect compilation](https://research.swtch.com/gomm#incorrect_compilation)

不正确的编译 Go 内存模型像限制 Go 程序一样限制了编译器优化。 一些在单线程程序中有效的编译器优化在 Go 程序中无效。 特别是，编译器不得在无竞争的程序中引入数据竞争。 它不能允许单个读取观察多个值。 并且它不能允许一次写入写入多个值。
    不将数据竞争引入无竞争程序意味着不将读取或写入从它们出现的条件语句中移出。 例如，编译器不得反转此程序中的条件：

```go
i := 0
if cond {
	i = *p
}
```

也就是说，编译器一定不能把程序改写成这样：

```go
i := *p
if !cond {
	i = 0
}
```

如果 cond 为 false 并且另一个 goroutine 正在编写 *p，那么原始程序是无竞争的，但重写的程序包含竞争。
   不引入数据竞争也意味着不假设循环终止。 例如，编译器不得在此程序中的循环之前移动对 *p 或 *q 的访问： 

```go
n := 0
for e := list; e != nil; e = e.next {
	n++
}
i := *p
*q = 1
```

如果 list 指向一个循环列表，那么原始程序将永远不会访问 *p 或 *q，但重写的程序会。
   不引入数据竞争也意味着不假设被调用的函数总是返回或没有同步操作。 例如，编译器不得在此程序中的函数调用之前移动对 *p 或 *q 的访问（至少在没有直接了解 f 的精确行为的情况下不能）： 

```go
f()
i := *p
*q = 1
```

如果调用从未返回，那么原始程序将永远不会访问 *p 或 *q，但重写的程序会。 如果调用包含同步操作，那么原始程序可以在访问 *p 和 *q 之前的边缘之前建立，但重写的程序不会。
    不允许单次读取观察多个值意味着不从共享内存重新加载局部变量。 例如，在这个程序中，编译器不能溢出 i 并从 *p 第二次重新加载它：

```go
i := *p
if i < 0 || i >= len(funcs) {
	panic("invalid function index")
}
... complex code ...
// compiler must NOT reload i = *p here
funcs[i]()
```

如果复杂代码需要许多寄存器，单线程程序的编译器可以丢弃 i 而不保存副本，然后在 funcs[i]() 之前重新加载 i = *p。  Go 编译器不能，因为 *p 的值可能已经改变。  （相反，编译器可能会将 i 溢出到堆栈中。）不允许一次写入写入多个值也意味着在写入之前不使用将写入局部变量的内存作为临时存储。 例如，编译器不得在此程序中使用 *p 作为临时存储：

```go
*p = i + *p/2
```

也就是说，它一定不能将程序改写成这样：

```go
*p /= 2
*p += i
```

如果 i 和 *p start 等于 2，则原始代码执行 *p = 3，因此赛车线程只能从 *p 读取 2 或 3。 重写的代码执行 *p = 1 然后 *p = 3，允许赛车线程也读取 1。
   请注意，所有这些优化在 C/C++ 编译器中都是允许的：与 C/C++ 编译器共享后端的 Go 编译器必须小心禁用对 Go 无效的优化。
   这些类别和示例涵盖了最常见的 C/C++ 编译器优化，这些优化与用于赛车数据访问的定义语义不兼容。 他们清楚地表明 Go 和 C/C++ 有不同的要求。

## [Conclusion](https://research.swtch.com/gomm#conclusion)

Go 在其内存模型中保守的一般方法对我们很有帮助，应该继续下去。 但是，有一些更改已过期，包括在 sync 和 sync/atomic 包中定义新 API 的同步行为。 特别是原子应该被记录下来，以提供顺序一致的行为，创建发生在边缘之前同步它们周围的非原子代码。 这将匹配所有其他现代系统语言提供的默认原子。
    更新中最独特的部分可能是明确声明具有数据竞争的程序可能会被停止以报告竞争，但否则具有明确定义的语义。 这限制了程序员和编译器，并且它优先考虑并发程序的可调试性和正确性，而不是编译器编写者的便利性。

## [Acknowledgements](https://research.swtch.com/gomm#acknowledgements)

这一系列的帖子从与我有幸在 Google 共事的一长串工程师的讨论和反馈中受益匪浅。 我要感谢他们。 我对任何错误或不受欢迎的意见承担全部责任。
